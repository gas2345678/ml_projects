{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f37b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import sentiment_analyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d95be79",
   "metadata": {},
   "source": [
    "Here are some text samples to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5372d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_animals= \"There is an example of many animals like dogs, cats, elephants, parrots, apes etc\"\n",
    "\n",
    "\n",
    "videogames = \"The best games of 2010-2020 decade are:\" \\\n",
    "\"The last of us- 2013\" \\\n",
    "\"GTA: San andreas- 2004\" \\\n",
    "\"Red dead Redemption- 2018\" \\\n",
    "\"As you can see, these are just examples, but there are many recognized AAA videogames around there.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f50fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2543c20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'is', 'an', 'example', 'of', 'many', 'animals', 'like', 'dogs', ',', 'cats', ',', 'elephants', ',', 'parrots', ',', 'apes', 'etc']\n"
     ]
    }
   ],
   "source": [
    "tokenized_words = word_tokenize(text=doc_animals,preserve_line=True,language=\"english\")\n",
    "print(tokenized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06a220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'best', 'games', 'of', '2010-2020', 'decade', 'are', ':', 'The', 'last', 'of', 'us-', '2013GTA', ':', 'San', 'andreas-', '2004Red', 'dead', 'Redemption-', '2018As', 'you', 'can', 'see', ',', 'these', 'are', 'just', 'examples', ',', 'but', 'there', 'are', 'many', 'recognized', 'AAA', 'videogames', 'around', 'there', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_games = word_tokenize(text=videogames,language=\"english\",preserve_line=True)\n",
    "print(tokenized_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c669f",
   "metadata": {},
   "source": [
    "To gather more information to process, we will make a request to this blog to get information about the netflix trends during the period of 2025 and apply a sentiment analysis for the different shows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8af4b2",
   "metadata": {},
   "source": [
    "We will create a function to perform these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87efe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_info(request):\n",
    "    gather_attem = re.get(request)\n",
    "    if gather_attem.status_code == 200:\n",
    "        gather_soup= BeautifulSoup(gather_attem)\n",
    "        pretty_gather = BeautifulSoup.prettify(gather_soup)\n",
    "        for word in pretty_gather.center:\n",
    "          word_tokenize(word)\n",
    "          sentiment_analyzer.apply_features(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429e090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
